{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('my_pytorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4aa4247aad03c0426ea4cd3b04a911f3f8b96c18bc1c724546bbedd590fde436"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "训练数据shape: (42000, 785)\n测试数据shape: (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('/Users/wangluya/PycharmProjects/datasets/digit_recognizer/train.csv')\n",
    "test_data = pd.read_csv('/Users/wangluya/PycharmProjects/datasets/digit_recognizer/test.csv')\n",
    "print(f'训练数据shape: {train_data.shape}')\n",
    "print(f'测试数据shape: {test_data.shape}')\n",
    "\n",
    "# 可以看到测试集合比训练集少一维，因为训练数据的第0列是类标签(0-9)， \n",
    "# 手写体数据实际上是一张28*28的矩阵，这里把这个矩阵平铺开了变成784维度的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbe72d0af10>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-03-30T15:40:51.069434</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 251.565 248.518125 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \nL 244.365 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pa715a45b6f)\">\n    <image height=\"218\" id=\"imagea94dae3ded\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m54df324258\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m54df324258\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m54df324258\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m54df324258\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m54df324258\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m54df324258\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m54df324258\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m15cb27eea6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m15cb27eea6\" y=\"11.082857\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m15cb27eea6\" y=\"49.911429\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m15cb27eea6\" y=\"88.74\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m15cb27eea6\" y=\"127.568571\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m15cb27eea6\" y=\"166.397143\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m15cb27eea6\" y=\"205.225714\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 224.64 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pa715a45b6f\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# 取一张图片看看\n",
    "import matplotlib.pyplot as plt\n",
    "one_img = test_data.iloc[0,:].values.reshape(28,28)\n",
    "plt.imshow(one_img, cmap=\"Greys\")"
   ]
  },
  {
   "source": [
    "# 建模\n",
    "+ __加载数据__\n",
    "+ __定义网络__\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape函数\n",
    "class ReshapeTransform:\n",
    "    def __init__(self, new_size, minmax=None):\n",
    "        self.new_size = new_size\n",
    "        self.minmax = minmax\n",
    "    def __call__(self, img):\n",
    "      if self.minmax:\n",
    "        img = img/self.minmax # 这里需要缩放到0-1，不然transforms.Normalize会报错\n",
    "      img = torch.from_numpy(img)\n",
    "      return torch.reshape(img, self.new_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset类，配合DataLoader使用\n",
    "class myDataset(Dataset):\n",
    "  def __init__(self, path, transform=None, is_train=True, seed=777):\n",
    "    \"\"\"\n",
    "    :param path:      文件路径\n",
    "    :param transform: 数据预处理\n",
    "    :param train:     是否是训练集\n",
    "    \"\"\"\n",
    "    self.data = pd.read_csv(path) # 读取数据\n",
    "    # 一般来说训练集会分为训练集和验证集，这里拆分比例为8: 2\n",
    "    if is_train: \n",
    "      self.data, _ = train_test_split(self.data, train_size=0.8, random_state=seed)\n",
    "    else:\n",
    "      _, self.data = train_test_split(self.data, train_size=0.8, random_state=seed)\n",
    "    self.transform = transform  # 数据转化器\n",
    "    self.is_train = is_train\n",
    "  def __len__(self):\n",
    "    # 返回data长度\n",
    "    return len(self.data)\n",
    "  def __getitem__(self, idx):\n",
    "    # 根据index返回一行\n",
    "    data, lab = self.data.iloc[idx, 1:].values, self.data.iloc[idx, 0]\n",
    "    if self.transform:\n",
    "      data = self.transform(data)\n",
    "    return data, lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理Pipeline\n",
    "transform = transforms.Compose([\n",
    "    ReshapeTransform((-1,28,28), 255),  # 一维向量变为28*28图片并且缩放(0-255)到0-1\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) ])# 均值方差标准化, (0.1307,), (0.3081,)是一个经验值不必纠结\n",
    "\n",
    "# 加载训练集\n",
    "train_data = myDataset('/Users/wangluya/PycharmProjects/datasets/digit_recognizer/train.csv', transform, True)\n",
    "train = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4)\n",
    "vail_data = myDataset('/Users/wangluya/PycharmProjects/datasets/digit_recognizer/train.csv', transform, False)\n",
    "vail = DataLoader(vail_data, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "# 加载测试集\n",
    "test_data = pd.read_csv('/Users/wangluya/PycharmProjects/datasets/digit_recognizer/test.csv')\n",
    "test_data = transform(test_data.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.2206,  2.8088,  2.8215,  0.5304,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242,  0.8232,  2.7960,  2.7960,  0.5177,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242,  1.0395,  2.7960,  2.7960,  0.5177,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242,  1.0395,  2.7960,  2.7960,  0.5177,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242,  0.2377,  1.7905,  1.3705,  0.0085, -0.4242,\n          -0.4242, -0.4242, -0.1951,  2.0578,  2.7960,  2.7960,  0.5177,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242,  1.6759,  2.7960,  2.7960,  2.1723, -0.4242,\n          -0.4242, -0.4115,  1.1414,  2.7960,  2.7960,  1.7141, -0.3351,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242,  1.7905,  2.7960,  2.7960,  2.2869, -0.4242,\n          -0.4242,  1.0013,  2.7960,  2.7960,  2.7960, -0.0424, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242,  1.1032,  2.7960,  2.7960,  2.7706,  0.6831,\n           1.5868,  2.7706,  2.7960,  1.7905,  0.1867, -0.3988, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.1951,  2.0960,  2.7960,  2.7960,  2.7960,\n           2.7960,  2.7960,  2.2105, -0.2969, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.0933,  2.6306,  2.7960,  2.7960,\n           2.7960,  1.4850, -0.3733, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.0806,  2.6306,  2.7960,  2.7960,\n           2.7960,  1.9942, -0.3733, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242,  1.2177,  2.7960,  2.7960,  2.5033,\n           2.7960,  2.7960,  2.0323, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.3606,  2.3251,  2.7960,  1.7905, -0.1187,\n           2.6815,  2.7960,  2.3887, -0.1187, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242,  0.5304,  2.7960,  2.7960,  0.1867, -0.4242,\n           0.4668,  2.6306,  2.7960,  1.6887, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242,  0.5431,  2.7960,  2.7960, -0.2460, -0.4242,\n          -0.4242,  1.5487,  2.7960,  2.6306, -0.3097, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242,  0.5304,  2.7960,  2.7960, -0.2460, -0.4242,\n          -0.4242,  0.9123,  2.7960,  2.7960,  1.0523, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.3478,  2.3505,  2.7960,  1.1795, -0.3097,\n          -0.4242,  0.9123,  2.7960,  2.7960,  1.9051, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242,  1.2177,  2.7960,  2.7960,  2.1723,\n           0.7468,  1.5741,  2.7960,  2.7960,  1.9051, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.0551,  2.6433,  2.7960,  2.7960,\n           2.7960,  2.7960,  2.7960,  2.7706,  0.5049, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242,  0.0849,  2.1596,  2.7960,\n           2.7960,  2.7960,  2.5033,  0.9250, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]],\n       dtype=torch.float64), 8)\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "source": [
    "+ __定义网络__\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了简单起见，这里定义一个两层卷积，两层全连接的网络\n",
    "# 初始化权重\n",
    "def _weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "# 建立网络\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3)\n",
    "        self.drop2d = nn.Dropout2d(p=0.2)\n",
    "        self.linr1 = nn.Linear(20*5*5, 32)\n",
    "        self.linr2 = nn.Linear(32, 10)\n",
    "        self.apply(_weight_init) # 初始化权重\n",
    "    # 正向传播 \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.drop2d(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.drop2d(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 20*5*5) # 卷积接全连接需要计算好卷积输出维度，将卷积输出结果平铺开\n",
    "        x = self.linr1(x)\n",
    "        x = F.dropout(x,p=0.5)\n",
    "        x = self.linr2(x)\n",
    "        return x\n",
    "net = Net()"
   ]
  },
  {
   "source": [
    "+ __定义优化器与损失函数__\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化器和损失函数\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005) # 使用Adam作为优化器\n",
    "criterion = nn.CrossEntropyLoss() # 损失函数为CrossEntropyLoss，CrossEntropyLoss()=log_softmax() + NLLLoss()\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5) # 这里使用StepLR，每十步学习率lr衰减50%"
   ]
  },
  {
   "source": [
    "+ __训练网络__"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch== 0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-38b70d74cbce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/my_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/my_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/my_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/my_pytorch/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/my_pytorch/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/my_pytorch/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_spawn_posix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mForkServerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/my_pytorch/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/my_pytorch/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/my_pytorch/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mfds_to_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 转化为GPU(可选)\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# if torch.cuda.is_available():\n",
    "#   net = net.to(device)\n",
    "#   criterion = criterion.to(device)\n",
    "device = 'cpu' \n",
    "epochs = 100\n",
    "loss_history = []\n",
    "# 训练模型\n",
    "for epoch in range(epochs):\n",
    "    print('epoch==',epoch)\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    with torch.set_grad_enabled(True):\n",
    "        net.train()\n",
    "        for batch, (data, target) in enumerate(train):\n",
    "            data = data.to(device).float()\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predict = net(data)\n",
    "            loss = criterion(predict, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "    scheduler.step() # 经过一个epoch，步长+1\n",
    "    with torch.set_grad_enabled(False):\n",
    "        net.eval() # 网络中有drop层，需要使用eval模式\n",
    "        for batch, (data, target) in enumerate(vail):\n",
    "            data = data.to(device).float()\n",
    "            target = target.to(device)\n",
    "            predict = net(data)\n",
    "            loss = criterion(predict, target)\n",
    "            val_loss.append(loss.item())\n",
    "    loss_history.append([np.mean(train_loss), np.mean(val_loss)])\n",
    "    print('epoch:%d train_loss: %.5f val_loss: %.5f' %(epoch+1, np.mean(train_loss), np.mean(val_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.7.1\nFalse\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}